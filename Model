# -*- coding: utf-8 -*-
"""Group16

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xaeV_1GfURoy3JjdCfNgnIjjhr0ePj_o

Authors:


Tarannum Al Akida 


### `1. Introduction:`
According to estimates from the World Health Organization, heart disease causes 12 million deaths globally each year. Cardiovascular diseases account for half of all deaths in the US and other affluent nations. Early diagnosis of cardiovascular disorders can help high-risk patients make lifestyle adjustments that will lessen problems. This study aims to identify the most significant risk factors for heart disease and use six models to forecast total risk.(`[KNN, Decision Tree, Logistic Regression, Linear Regression, Naive Bayes, Neural Network.]`).

### `2. About Dataset(Description)`

#### Background:
This is a multivariate type of dataset which means providing or involving a variety of separate mathematical or statistical variables, multivariate numerical data analysis. It is composed of 14 attributes which are age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise-induced angina, oldpeak â€” ST depression induced by exercise relative to rest, the slope of the peak exercise ST segment, number of major vessels and Thalassemia. This database includes 76 attributes, but all published studies relate to the use of a subset of 14 of them. The Cleveland database is the only one used by ML researchers to date. One of the major tasks on this dataset is to predict based on the given attributes of a patient that whether that particular person has heart disease or not and other is the experimental task to diagnose and find out various insights from this dataset which could help in understanding the problem more.

### Content
#### Column Descriptions:
* `id `(Unique id for each patient)
* `age` (Age of the patient in years)
* `origin` (place of study)
* `sex` (Male/Female)
* `cp` chest pain type
  1. typical angina.
  2. atypical angina.
  3. non-anginal.
  4. asymptomatic.
* `trestbps` resting blood pressure (resting blood pressure (in mm Hg on admission to the hospital))
* `chol` (serum cholesterol in mg/dl)
* `fbs` (if fasting blood sugar > 120 mg/dl)
* `restecg` (resting electrocardiographic results)
* `-- Values:` [normal, stt abnormality, lv hypertrophy]
* `thalach:` maximum heart rate achieved
* `exang:` exercise-induced angina (True/ False)
* `oldpeak:` ST depression induced by exercise relative to rest
* `slope:` the slope of the peak exercise ST segment
* `ca:` number of major vessels (0-3) colored by fluoroscopy
* `thal:`[normal; fixed defect; reversible defect]
* `num:` the predicted attribute
"""

import pandas as pd
import numpy as np
df = pd.read_csv('heart_disease.csv')

# 2. To Viusalize the data
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
# from yellowbrick.cluster import KElbowVisualizer
from matplotlib.colors import ListedColormap

# 3. To preprocess the data

from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer, KNNImputer

# 4. import Iterative imputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

# 5. Machine Learning
from sklearn.model_selection import train_test_split, KFold, cross_val_score

# 6. For Classification task.
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,RandomForestRegressor
from sklearn.cluster import KMeans
# 7. Metrics
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

# 8. Ignore warnings
import warnings
warnings.filterwarnings('ignore')

df.shape

df.head()

df.info()

print(f"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset.")

print(f"The target column is {df['num']}")

print(f'How many features? Answer: {df.shape[1]-1} features')

print("It is a Classification problem because the target column has categorical values (0 or 1-4).")

print(f'the target variable has {df["num"].nunique()} classes, so it is a multi-class classification problem.')

print(f"There are {df.shape[0]} data points in the dataset.")

print(f'There are many kinds of features in the dataset such as:\n{df.dtypes.value_counts()}')
print(f'These are two kinds of features such as: Quantitative and categorical features.')

print(f'Quantitative or numerical features: {df.select_dtypes(include=np.number).columns.tolist()[0:-1]}')
print(f'Numerical columns: {df.select_dtypes(include=np.number).columns.tolist()}')

print(f'Categorical features: {df.select_dtypes(include="object").columns.tolist()}')

# Do you need to encode the categorical variables, why or why not?
print(f'Yes, we need to encode the categorical variables because machine learning algorithms can only understand numerical values.\nEncoding transforms these categories into numerical form without introducing order where none exists.')
print('we can use label encoding or one-hot encoding to convert categorical variables into numerical values.')

#For nominal variables (no inherent order), use One-Hot Encoding (creates binary columns for each category).
#For ordinal variables (have a natural order, like severity levels low/medium/high),
#use Label Encoding or map them to integers reflecting their order.'''

numerical_data = df.select_dtypes(include='number')
numerical_features=numerical_data.columns.tolist()

numerical_features.remove('num')  # Remove target variable if present
print(numerical_features)
print(f'There are {len(numerical_features)} numerical input features:', '\n')

categorical_data=df.select_dtypes(include= 'object')
categorical_features=categorical_data.columns.tolist()
print(f'There are {len(categorical_features)} numerical features:', '\n')
print(categorical_features)

# Correlation of all the features (input and output features) (apply heatmap using the seaborn library)
corr_matrix = df.corr(numeric_only=True)
plt.figure(figsize=(7, 5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Feature Correlation Heatmap')
plt.show()

"""Imbalanced Dataset
-For the output feature,
do all unique classes have an equal number of instances or not?
Answer: NO.


Represent using a bar chart of N classes (N=number of classes you have in your dataset).
"""

output_column = 'num'
class_counts = df[output_column].value_counts().sort_index()
print("Class Distribution:\n", class_counts)
plt.figure(figsize=(7, 5))
class_counts.plot(kind='bar', color='blue', alpha=0.7)
plt.xlabel('Class')
plt.ylabel('Number of Instances')
plt.title(f'Class Distribution in Output Feature ({output_column})')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

#What do you understand after the correlation test?
"""
Correlation analysis helps identify the most relevant features for prediction.

It highlights potential redundancy between features.

These insights guide feature selection, preprocessing, and the choice of algorithms.
"""

print(f'The output feature {output_column} has {class_counts.idxmax()} class with the highest number of instances ({class_counts.max()}) and {class_counts.idxmin()} class with the lowest number of instances ({class_counts.min()}).  This indicates class imbalance, which may require techniques like resampling or class weighting during model training to ensure fair learning across all classes.')

#After Performing exploratory data analysis to extract some important relationships from your data.
print("Exploratory Data Analysis (EDA) Insights:")
"""Strong predictors: chest pain type, oldpeak, ca (major vessels), slope.

Supporting predictors: age, sex, cholesterol, thalach.

The dataset shows class imbalance and some multicollinearity, both of which should be addressed in modeling."""

"""### `2. Data Pre-processing`

Handling missing values:
for numerical, we use mean to impute.
for categorical, we use mode to impute.
"""

print(f"There are missing values in the dataset:\n{df.isnull().sum()}")

imputer1 = IterativeImputer(max_iter=10, random_state=42)

# Fit the imputer on trestbps column
imputer1.fit(df[['trestbps']])

# Transform the data
df['trestbps'] = imputer1.transform(df[['trestbps']])

# Check the missing values in trestbps column
print(f"Missing values in trestbps column: {df['trestbps'].isnull().sum()}")

df.info()

# let's see which columns has missing values
(df.isnull().sum()/ len(df)* 100).sort_values(ascending=False)

"""selected columns are:
1. ca.
2. oldpeak
3. thal
4. chol
5. thalch
"""

# create an object of iterative imputer
imputer2 = IterativeImputer(max_iter=10, random_state=42)

# fit transform on ca,oldpeak, thal,chol and thalch columns
df['ca'] = imputer2.fit_transform(df[['ca']])
df['oldpeak']= imputer2.fit_transform(df[['oldpeak']])
df['chol'] = imputer2.fit_transform(df[['chol']])
df['thalch'] = imputer2.fit_transform(df[['thalch']])

# let's check again for missing values
(df.isnull().sum()/ len(df)* 100).sort_values(ascending=False)

"""Now, object or categorical data imputation"""

print(f"The missing values in thal column are: {df['thal'].isnull().sum()}")

df['thal'].value_counts()

df.tail()

"""### Steps to dealing with Missing  values (Categorical with Machine learning Models):

1. FInd the collumns with missing values and store in an object
3. FInd the Columns based on data type
    1. Numeric columns.
    2. Categorical Columns.
    3. Boolean.
4. Define the function to impute missing values.
5. Apply the function to our dataset with missing values.
6. Check the missing values after imputation.
"""

df.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False)

missing_data_cols = df.isnull().sum()[df.isnull().sum()>0].index.tolist()

missing_data_cols

# find categorical Columns
cat_cols = df.select_dtypes(include='object').columns.tolist()
cat_cols

# find Numerical Columns
Num_cols = df.select_dtypes(exclude='object').columns.tolist()
Num_cols

print(f'categorical Columns: {cat_cols}')
print(f'numerical Columns: {Num_cols}')

categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','fbs', 'cp', 'sex', 'num']
bool_cols = ['fbs', 'exang']
numerical_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']

#to impute categorical columns
def impute_categorical_missing_data(passed_col):

    df_null = df[df[passed_col].isnull()]
    df_not_null = df[df[passed_col].notnull()]

    X = df_not_null.drop(passed_col, axis=1)
    y = df_not_null[passed_col]

    other_missing_cols = [col for col in missing_data_cols if col != passed_col]

    label_encoder = LabelEncoder()
    for col in X.columns:
        if X[col].dtype == 'object' or X[col].dtype == 'category':
            X[col] = label_encoder.fit_transform(X[col])

    if passed_col in bool_cols:
        y = label_encoder.fit_transform(y)

    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)

    for col in other_missing_cols:
        if X[col].isnull().sum() > 0:
            col_with_missing_values = X[col].values.reshape(-1, 1)
            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)
            X[col] = imputed_values[:, 0]
        else:
            pass

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    rf_classifier = RandomForestClassifier()

    rf_classifier.fit(X_train, y_train)

    y_pred = rf_classifier.predict(X_test)

    acc_score = accuracy_score(y_test, y_pred)

    print("The feature '"+ passed_col+ "' has been imputed with", round((acc_score * 100), 2), "accuracy\n")

    X = df_null.drop(passed_col, axis=1)

    for col in X.columns:
        if X[col].dtype == 'object' or X[col].dtype == 'category':
            X[col] = label_encoder.fit_transform(X[col])

    for col in other_missing_cols:
        if X[col].isnull().sum() > 0:
            col_with_missing_values = X[col].values.reshape(-1, 1)
            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)
            X[col] = imputed_values[:, 0]
        else:
            pass

    if len(df_null) > 0:
        df_null[passed_col] = rf_classifier.predict(X)
        if passed_col in bool_cols:
            df_null[passed_col] = df_null[passed_col].map({0: False, 1: True})
        else:
            pass
    else:
        pass

    df_combined = pd.concat([df_not_null, df_null])

    return df_combined[passed_col]

def impute_continuous_missing_data(passed_col):

    df_null = df[df[passed_col].isnull()]
    df_not_null = df[df[passed_col].notnull()]

    X = df_not_null.drop(passed_col, axis=1)
    y = df_not_null[passed_col]

    other_missing_cols = [col for col in missing_data_cols if col != passed_col]

    label_encoder = LabelEncoder()

    for col in X.columns:
        if X[col].dtype == 'object' or X[col].dtype == 'category':
            X[col] = label_encoder.fit_transform(X[col])

    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)

    for col in other_missing_cols:
        if X[col].isnull().sum() > 0:
            col_with_missing_values = X[col].values.reshape(-1, 1)
            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)
            X[col] = imputed_values[:, 0]
        else:
            pass

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    rf_regressor = RandomForestRegressor()

    rf_regressor.fit(X_train, y_train)

    y_pred = rf_regressor.predict(X_test)

    print("MAE =", mean_absolute_error(y_test, y_pred), "\n")
    print("RMSE =", mean_squared_error(y_test, y_pred, squared=False), "\n")
    print("R2 =", r2_score(y_test, y_pred), "\n")

    X = df_null.drop(passed_col, axis=1)

    for col in X.columns:
        if X[col].dtype == 'object' or X[col].dtype == 'category':
            X[col] = label_encoder.fit_transform(X[col])

    for col in other_missing_cols:
        if X[col].isnull().sum() > 0:
            col_with_missing_values = X[col].values.reshape(-1, 1)
            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)
            X[col] = imputed_values[:, 0]
        else:
            pass

    if len(df_null) > 0:
        df_null[passed_col] = rf_regressor.predict(X)
    else:
        pass

    df_combined = pd.concat([df_not_null, df_null])

    return df_combined[passed_col]
passed_col = categorical_cols

df.isnull().sum().sort_values(ascending=False)

#impute missing values using our functions
for col in missing_data_cols:
    print("Missing Values", col, ":", str(round((df[col].isnull().sum() / len(df)) * 100, 2))+"%")
    if col in categorical_cols:
        df[col] = impute_categorical_missing_data(col)
    elif col in numeric_cols:
        df[col] = impute_continuous_missing_data(col)
    else:
        pass

df.isnull().sum().sort_values(ascending=False)

"""Missing value handled."""

df.info()

df.columns

df.head()

"""Targeted column = `num` its a predicted attribute.


We'll use this column to predict the heart disease.
The unique values in this column are: [0,1,2,3,4], which states that there are 5 types of heart diseases.
* `0 = no heart disease.`
* `1 = Mild Heart Disease types.`
* `2 = Moderate Heart Disease type.`
* `3 =  Severe Heart Disease type.`
* `4 =  Critical Heart Disease type.`

### `4.	Dataset splitting`
"""

X= df.drop('num', axis=1)
y = df['num']

"""encode X data using separate label encoder for all categorical columns and save it for inverse transform"""
# Task: Separate Encoder for all categorical and object columns and inverse transform at the end.
Label_Encoder = LabelEncoder()

for col in X.columns:
    if X[col].dtype == 'object' or X[col].dtype == 'category':
        X[col] = Label_Encoder.fit_transform(X[col])
    else:
        pass


# split the data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

"""### `5. Model Training`

[KNN, Decision Tree, Logistic Regression, Linear Regression, Naive Bayes, Neural Network.]
"""

models = [
    ('Logistic Regression', LogisticRegression(random_state=42)),
    ('KNeighbors Classifier', KNeighborsClassifier()),
    ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)),
    ('Naye base Classifier', GaussianNB()),
    ('Nueral Network', MLPClassifier(random_state=42))
]

best_model = None
best_accuracy = 0.0

#Iterate over the models and evaluate their performance
for name, model in models:
    #create a pipeline for each model
    pipeline = Pipeline([
        # ('imputer', SimpleImputer(strategy='most_frequent)),
        #('encoder', OneHotEncoder(handle_unknow='ignore'))
        ('model', model)
    ])

    # perform cross validation
    scores = cross_val_score(pipeline, X_train, y_train, cv=5)

    # Calculate mean accuracy
    mean_accuracy = scores.mean()

    #fit the pipeline on the training data
    pipeline.fit(X_train, y_train)

    # make prediction on the test data
    y_pred = pipeline.predict(X_test)

    #Calculate accuracy score
    accuracy = accuracy_score(y_test, y_pred)

    #print the performance metrics
    print("Model", name)
    print("Cross Validatino accuracy: ", mean_accuracy)
    print("Test Accuracy: ", accuracy)
    print()

    #Check if the current model has the best accuracy
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_model = pipeline

# Retrieve the best model
print("Best Model: ", best_model)
print(f'Best accuracy: {best_accuracy}')

"""### for unsupervised:"""

df.info()

df.isnull().sum()

# Separate features (X) and target (y)
X = df.drop('num', axis=1)
y = df['num']

# Define pipelines for numerical and categorical features
numerical_features = X.select_dtypes(include=np.number).columns
categorical_features = X.select_dtypes(exclude=np.number).columns

numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

categorical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Create a preprocessor to handle both feature types
preprocessor = ColumnTransformer(transformers=[
    ('num', numerical_pipeline, numerical_features),
    ('cat', categorical_pipeline, categorical_features)
])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Apply the preprocessing steps
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

import os
os.environ['OMP_NUM_THREADS'] = '3'

inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_train_processed)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(8, 6))
plt.plot(K, inertia, 'bx-')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Inertia')
plt.title('The Elbow Method for Optimal k')
plt.show()

"""elbow method, taking 4 clusters."""

kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
clusters = kmeans.fit_predict(X_train_processed)

# Visualize the clusters using the first two processed features
plt.figure(figsize=(8, 6))
plt.scatter(X_train_processed[:, 0], X_train_processed[:, 1], c=clusters, cmap='viridis', alpha=0.8)
plt.title('K-Means Clustering of Processed Training Data')
plt.xlabel('Processed Feature 1')
plt.ylabel('Processed Feature 2')
plt.show()

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_curve, auc, confusion_matrix, classification_report, log_loss
)
from sklearn.preprocessing import label_binarize

models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Neural Network': MLPClassifier(random_state=42, max_iter=1000)
}

results = {}
classes = np.unique(y_train)

for name, model in models.items():
    model.fit(X_train_processed, y_train)
    y_pred = model.predict(X_test_processed)

    # Base metrics
    results[name] = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),
        'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),
        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0)
    }

    # Log Loss (if predict_proba available)
    if hasattr(model, "predict_proba"):
        y_pred_proba = model.predict_proba(X_test_processed)
        results[name]['log_loss'] = log_loss(y_test, y_pred_proba, labels=classes)

    print(f'--- {name} ---')
    print(classification_report(y_test, y_pred, zero_division=0))

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
    plt.title(f'Confusion Matrix: {name}')
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

    # ROC Curve (One-vs-Rest for multiclass)
    if hasattr(model, "predict_proba"):
        y_pred_proba = model.predict_proba(X_test_processed)
        y_test_bin = label_binarize(y_test, classes=classes)

        plt.figure()
        for i, class_label in enumerate(classes):
            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])
            roc_auc = auc(fpr, tpr)
            plt.plot(fpr, tpr, lw=2, label=f'Class {class_label} (AUC = {roc_auc:.2f})')

        plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
        plt.title(f'ROC Curve: {name}')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.legend(loc='lower right')
        plt.show()

    # Loss curve (only for MLPClassifier)
    if hasattr(model, "loss_curve_"):
        plt.plot(model.loss_curve_, marker='o')
        plt.title(f'Loss Curve: {name}')
        plt.xlabel('Iterations')
        plt.ylabel('Loss')
        plt.show()

    print('\n' + '='*50 + '\n')

results_df = pd.DataFrame(results).T
print("Model Performance Comparison Summary:")
display(results_df)

results_df.plot(kind='bar', figsize=(12, 7))
plt.title('Comparison of Model Performance Metrics')
plt.ylabel('Score')
plt.xticks(rotation=30, ha='right')
plt.ylim(0, 1)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

kf = KFold(n_splits=5, shuffle=True, random_state=42)

print("K-Fold Cross-Validation Results:\n")
for name, model in models.items():
    # Create a pipeline that includes preprocessing and the model to prevent data leakage
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])

    cv_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='accuracy')

    print(f'--- {name} ---')
    print(f'Fold Accuracies: {cv_scores}')
    print(f'Average Accuracy: {np.mean(cv_scores):.3f}')
    print(f'Standard Deviation: {np.std(cv_scores):.3f}\n')

"""The database that was tested on:"""

df.info()

df.isnull().sum()

"""Best models is Linear/logistic regression

### Conclusion

This analysis demonstrates the successful application of various machine learning models to the complex problem of heart disease prediction. The results indicate that several models, particularly **Logistic Regression**, achieve high performance in classifying patients. The comprehensive evaluation, including metrics like precision, recall, and AUC, provides a nuanced understanding of each model's strengths and weaknesses. The K-Fold Cross-Validation confirms the robustness of our findings.

**Key Challenges & Learnings:**
- **Data Quality**: The presence of missing values necessitated a robust preprocessing pipeline to ensure data integrity.
- **Feature Engineering**: The mix of categorical and numerical features required a careful and systematic approach to encoding and scaling.
- **Model Evaluation**: Relying on a single metric like accuracy would have been misleading. A holistic evaluation using multiple metrics was crucial for selecting the best model.

Overall, this project provides a solid foundation for developing a clinical decision support tool for heart disease diagnosis.
"""
